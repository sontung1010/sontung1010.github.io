---
title: "Intelligent Navigation of Autonomous Maritime Robots (Work in Progress)"
excerpt: "<b>Skills:</b> ROS, ROS2, Rviz, Gazebo, PyTorch, TensorFlow, U-Net, OpenCV, Python, C++, Linux, Bash/Shell Scripting, Git, Docker, Microcontroller, SolidWorks, 3D printing<br/><img src='/images/usv.png'>"
collection: portfolio
---


<div>
    <b>Supervisors:</b> <a href="https://fieldrobotics.engin.umich.edu/team" target="_blank">Prof. Katherine A. Skinner</a> and <a href="https://www.linkedin.com/in/elena-shrestha/" target="_blank">Dr. Elena Shrestha</a><br>
</div>
<br>


<div>
    <p>
        <b>Brief:</b> While reinforcement learning offers potential for continual learning and adaptability in complex scenarios, its application to real-world robotics faces significant challenges. Unlike in simulations, physical platforms struggle to collect a diverse corpus of training data due to critical safety risks and the inherent constraints of operating within a dynamic and partially observable environment. Our work draws inspiration from the human capability to fuse and exploit multiple sensing modalities, construct comprehensive models of how the world operates, and then leverage those models to adeptly navigate in challenging and often unpredictable environments. Here is an overview of how unmanned vehicles (ground, air, and surface) can exploit a world model constructed through multimodal perception, to learn near-optimal policies for guidance and control. A key aspect of the approach is learning from imagination in which the world model is used to simulate future imagined trajectories, enabling it to anticipate potential risks before encountering them in the real world. Our ongoing work and long-term vision is to evolve the traditional sense-plan-act framework into a more intuitive and cognitively inspired sense-imagine-act model. <a href="https://www.youtube.com/watch?v=Orte6Uv_mGU&t=987s" target="_blank">Dr. Elena Shrestha's presentation of our research.</a>

    </p>
</div>


<div>
    <p>
        <b>Role:</b> Graduate Research Assistant, <b>Field Robotics Group</b><br>
    </p>
</div>

<div>
    <p>
        <b>Autonomous Maritime Navigation Challenges:</b><br>
        - Varying weather conditions, unpredictable currents, rough seas, and strong winds<br>
        - Difficult to collecting realistic training data<br>
        - Noisy sensor measurements<br>
        - Model uncertainty (dynamics)<br>
        - Reduced performance and reliability<br>
        - Real-time decision-making is essential<br>
        - The limitations of onboard hardware<br>
        - Complex, unstructured environments<br>
        - Stochastic nature of environment<br>
        - Localization and mapping<br>
        - Power (battery) efficiency management<br>
    </p>
    <img src="/images/USV/heron_banner.jpg"><br>
</div>
<br>

<div>
    <p>
        <b>Goal: </b> This project aims to overcome these obstacles, enabling the successful deployment and operation of USVs in novel and unpredictable environments, using our MBRL model.<br>
    </p>
</div>
<br>
<div>
    <p>
        <b>Why Model-based Reinforcement Learning (MBRL)?</b><br>
        - Better Adaptation: Learns an internal model of the environment, helping it adapt to new policies and conditions, unlike model-free RL, which relies only on previous experience.<br>
        - Faster Learning: Learns efficiently with fewer interactions than model-free RL, saving time and reducing the need for costly or risky data collection.<br>
        - Clearer Decisions: Tracks important details about the environment, making it easier to understand and improve the agent’s behavior.<br>
        - Stronger Sensor Integration: Combines inputs from multiple sensors (like LiDAR and cameras), giving a more accurate view of surroundings.<br>
        - Safer High-Speed Control: Plans actions with an awareness of dynamics, balancing speed with safety, ideal for real-time sudden scenarios.<br>
    </p>
</div>
<br>
<div>
    <p>
        <b>Related Work in MBRL for USV Path Planning</b>
        <img src="/images/USV/path_planning_comparison.png"><br>
    </p>
</div>


<div>
    <p>
        <b>Contribution:</b><br>
        Worked on “Intelligent Navigation of Autonomous Maritime Robots” towards a publication as the second author<br>
        - Labeled and processed a 2,230-image dataset to train a U-Net segmentation model for applying the Lucid Dreamer model on the USV, which enhances the USV’s perception capabilities and enables improved trajectory planning and navigation in dynamic environments.<br>
        - Designed and tested an object avoidance algorithm in Python and C++, demonstrating simulation success and contributing to optimizing the USV’s control systems for benchmarking autonomous navigation.<br>
        - Conducted real-world navigation tests under varying wave and obstacle conditions to collect sensor data (LiDAR, camera, IMU, GPS, odometry) for multimodal data fusion. Implemented frame alignment and timestamp synchronization to improve Hector SLAM accuracy and performance analysis in RViz.<br>
        - Developed a URDF model for the Heron USV in ROS2 and Gazebo Garden to create a realistic simulation environment for testing navigation algorithms and collecting more training data.<br>
        - Prepared the Heron USV for deployment by configuring battery, electrical, and mechanical systems, maintaining its functionality for every test. Designed and 3D-printed custom sensor mounts to integrate and calibrate sensors accurately, ensuring synchronized data acquisition.<br>

    </p>
</div>
<div>
    <iframe width="420" height="315"
    src="https://youtube.com/embed/gSU9hapYx8s" 
    title="Heron"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
    allowfullscreen>
    </iframe>
    <center>
        Simulation: Autonomous Object Avoidance
    </center>
</div>
<br>
<div>
    <iframe width="420" height="315"
    src="https://youtube.com/embed/Aa0qp4Q8fms" 
    title="Heron"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
    allowfullscreen>
    </iframe>
    <center>
        Real-world test: Autonomous Object Avoidance
    </center>
</div>
<br>


<div>
    <p>
        [<a href="" target="_blank">GitHub</a>][<a href="https://sontung1010.github.io/publication/2024-12-12-Intelligent-Navigation-of-Autonomous-Maritime-Robots" target="_blank">Publication</a>][<a href="https://docs.google.com/presentation/d/19Tz14ShtI7ksQvZ1I69B2yNZBIIl61KKa4lkgYfz3p8/edit?usp=sharing" target="_blank">Slide</a>]
    </p>
    <p>
        <b>Skills:</b> ROS, ROS2, Rviz, Gazebo, PyTorch, TensorFlow, U-Net, OpenCV, Python, C++, Linux, Bash/Shell Scripting, Git, Docker, Microcontroller, SolidWorks, 3D printing<br>
        <b>Contributors' Acknowledgement:</b> Prof. Katherine A. Skinner, Dr. Elena Shrestha, Kathryn Wakevainen, Jingyu Song, Surya Singh
    </p>
</div>